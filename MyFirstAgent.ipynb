{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My First Agent\n",
    "\n",
    "\n",
    "I am following the tutorial from this webpage:\n",
    "https://python.langchain.com/docs/tutorials/\n",
    "\n",
    "My goal is to create something that anyone can run from COLAB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.63)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.43)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-community in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (0.3.24)\n",
      "Requirement already satisfied: pypdf in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (5.5.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.3.63)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (3.12.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.3.43)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-core langgraph>0.2.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --quiet langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-core in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (0.3.63)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core) (0.3.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langchain-core) (2.11.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core) (2.2.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/christopherwaight/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade langchain-core\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SetUp Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to OPEN AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 20, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Be58KyQPdATSuSybSAV8RGibXtsE8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bbb628d9-3a2e-474d-8d97-69d210aaa989-0', usage_metadata={'input_tokens': 20, 'output_tokens': 3, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Note, the following are equivalent:  \n",
    "\n",
    "model.invoke(\"Hello\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"Hello\")]) \n",
    "\n",
    "\n",
    "### To see how many tokens are in the answer:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|C|iao|!||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template\n",
    "\n",
    "\n",
    "For more prompt templates, go here:  \n",
    "\n",
    "https://python.langchain.com/docs/how_to/#prompt-templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the llm\n",
    "\n",
    "This uses the prompts we set up and runs the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents and Document Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Example of very simple documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading PDF's \n",
    "\n",
    "Be sure to update the path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"nke-10k-2023.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This splits it into 1 page ==  1 doc. We may need something a bit more granular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents\n",
      "UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "FORM 10-K\n",
      "(Mark One)\n",
      "☑  ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "F\n",
      "\n",
      "{'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': 'nke-10k-2023.pdf', 'total_pages': 107, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{docs[0].page_content[:200]}\\n\")\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Langchain to split the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings \n",
    "\n",
    "I need an embeddings model too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of length 3072\n",
      "\n",
      "[0.009356783702969551, -0.01619010977447033, 0.00035251901135779917, 0.006321138236671686, 0.020612407475709915, -0.03930098935961723, -0.007439204957336187, 0.04112487658858299, -0.008088808506727219, 0.0595136396586895]\n"
     ]
    }
   ],
   "source": [
    "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
    "print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Stores \n",
    "\n",
    "\n",
    "in Langchain Vectore objects contain methods for adding text and Document Objects to the store, and quering them using various similiarity metics.  \n",
    "\n",
    "They are oftem initialized with embedding models, which determine how text data is translated into numeric vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using chromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Instantiating the vector store\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing the documents in the database\n",
    "\n",
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Documents based on similiarity to a string query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='operations. We also lease an office complex in Shanghai, China, our headquarters for our Greater China geography, occupied by employees focused on implementing our\n",
      "wholesale, NIKE Direct and merchandising strategies in the region, among other functions.\n",
      "In the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of which are owned and three of which are\n",
      "leased. Two other distribution centers, one located in Indianapolis, Indiana and one located in Dayton, Tennessee, are leased and operated by third-party logistics\n",
      "providers. One distribution center for Converse is located in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States,\n",
      "some of which are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United States are located in Laakdal,' metadata={'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'creator': 'EDGAR Filing HTML Converter', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'page': 26, 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'start_index': 804, 'source': 'nke-10k-2023.pdf', 'title': '0000320187-23-000039', 'page_label': '27', 'moddate': '2023-07-20T16:22:08-04:00', 'creationdate': '2023-07-20T16:22:00-04:00', 'keywords': '0000320187-23-000039; ; 10-K', 'total_pages': 107}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"How many distribution centers does Nike have in the US?\"\n",
    ")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Table of Contents\n",
      "PART I\n",
      "ITEM 1. BUSINESS\n",
      "GENERAL\n",
      "NIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \"Annual Report\"), the terms \"we,\" \"us,\" \"our,\"\n",
      "\"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries and affiliates, collectively, unless the context indicates otherwise.\n",
      "Our principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, equipment, accessories and services. NIKE is\n",
      "the largest seller of athletic footwear and apparel in the world. We sell our products through NIKE Direct operations, which are comprised of both NIKE-owned retail stores\n",
      "and sales through our digital platforms (also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales' metadata={'start_index': 0, 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'total_pages': 107, 'page': 3, 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'moddate': '2023-07-20T16:22:08-04:00', 'title': '0000320187-23-000039', 'page_label': '4', 'creationdate': '2023-07-20T16:22:00-04:00', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'source': 'nke-10k-2023.pdf', 'creator': 'EDGAR Filing HTML Converter', 'keywords': '0000320187-23-000039; ; 10-K'}\n"
     ]
    }
   ],
   "source": [
    "results = await vector_store.asimilarity_search(\"When was Nike incorporated?\")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Similiarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6225528717041016\n",
      "\n",
      "page_content='Table of Contents\n",
      "FISCAL 2023 NIKE BRAND REVENUE HIGHLIGHTSThe following tables present NIKE Brand revenues disaggregated by reportable operating segment, distribution channel and major product line:\n",
      "FISCAL 2023 COMPARED TO FISCAL 2022\n",
      "• NIKE, Inc. Revenues were $51.2 billion in fiscal 2023, which increased 10% and 16% compared to fiscal 2022 on a reported and currency-neutral basis, respectively.\n",
      "The increase was due to higher revenues in North America, Europe, Middle East & Africa (\"EMEA\"), APLA and Greater China, which contributed approximately 7, 6,\n",
      "2 and 1 percentage points to NIKE, Inc. Revenues, respectively.\n",
      "• NIKE Brand revenues, which represented over 90% of NIKE, Inc. Revenues, increased 10% and 16% on a reported and currency-neutral basis, respectively. This\n",
      "increase was primarily due to higher revenues in Men's, the Jordan Brand, Women's and Kids' which grew 17%, 35%,11% and 10%, respectively, on a wholesale\n",
      "equivalent basis.' metadata={'page': 35, 'start_index': 0, 'page_label': '36', 'creationdate': '2023-07-20T16:22:00-04:00', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'title': '0000320187-23-000039', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'moddate': '2023-07-20T16:22:08-04:00', 'keywords': '0000320187-23-000039; ; 10-K', 'creator': 'EDGAR Filing HTML Converter', 'source': 'nke-10k-2023.pdf', 'total_pages': 107}\n"
     ]
    }
   ],
   "source": [
    "# Note that providers implement different scores; the score here\n",
    "# is a distance metric that varies inversely with similarity.\n",
    "\n",
    "results = vector_store.similarity_search_with_score(\"What was Nike's revenue in 2023?\")\n",
    "doc, score = results[0]\n",
    "print(f\"Score: {score}\\n\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Table of Contents\n",
      "GROSS MARGIN\n",
      "FISCAL 2023 COMPARED TO FISCAL 2022\n",
      "For fiscal 2023, our consolidated gross profit increased 4% to $22,292 million compared to $21,479 million for fiscal 2022. Gross margin decreased 250 basis points to\n",
      "43.5% for fiscal 2023 compared to 46.0% for fiscal 2022 due to the following:\n",
      "*Wholesale equivalent\n",
      "The decrease in gross margin for fiscal 2023 was primarily due to:\n",
      "• Higher NIKE Brand product costs, on a wholesale equivalent basis, primarily due to higher input costs and elevated inbound freight and logistics costs as well as\n",
      "product mix;\n",
      "• Lower margin in our NIKE Direct business, driven by higher promotional activity to liquidate inventory in the current period compared to lower promotional activity in\n",
      "the prior period resulting from lower available inventory supply;\n",
      "• Unfavorable changes in net foreign currency exchange rates, including hedges; and\n",
      "• Lower off-price margin, on a wholesale equivalent basis.\n",
      "This was partially offset by:' metadata={'source': 'nke-10k-2023.pdf', 'title': '0000320187-23-000039', 'creationdate': '2023-07-20T16:22:00-04:00', 'creator': 'EDGAR Filing HTML Converter', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'page_label': '37', 'start_index': 0, 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'moddate': '2023-07-20T16:22:08-04:00', 'total_pages': 107, 'keywords': '0000320187-23-000039; ; 10-K', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'page': 36}\n"
     ]
    }
   ],
   "source": [
    "embedding = embeddings.embed_query(\"How were Nike's margins impacted in 2023?\")\n",
    "\n",
    "results = vector_store.similarity_search_by_vector(embedding)\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='14b2fdd1-9313-477c-ae19-cfa69b0ef99d', metadata={'total_pages': 107, 'page_label': '27', 'start_index': 804, 'creationdate': '2023-07-20T16:22:00-04:00', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'title': '0000320187-23-000039', 'source': 'nke-10k-2023.pdf', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'page': 26, 'moddate': '2023-07-20T16:22:08-04:00', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'keywords': '0000320187-23-000039; ; 10-K', 'creator': 'EDGAR Filing HTML Converter'}, page_content='operations. We also lease an office complex in Shanghai, China, our headquarters for our Greater China geography, occupied by employees focused on implementing our\\nwholesale, NIKE Direct and merchandising strategies in the region, among other functions.\\nIn the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of which are owned and three of which are\\nleased. Two other distribution centers, one located in Indianapolis, Indiana and one located in Dayton, Tennessee, are leased and operated by third-party logistics\\nproviders. One distribution center for Converse is located in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States,\\nsome of which are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United States are located in Laakdal,')],\n",
       " [Document(id='ebca5a74-51cd-4253-aaf6-b650c3646f49', metadata={'creator': 'EDGAR Filing HTML Converter', 'start_index': 0, 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'source': 'nke-10k-2023.pdf', 'total_pages': 107, 'page_label': '4', 'moddate': '2023-07-20T16:22:08-04:00', 'page': 3, 'keywords': '0000320187-23-000039; ; 10-K', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions'}, page_content='Table of Contents\\nPART I\\nITEM 1. BUSINESS\\nGENERAL\\nNIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \"Annual Report\"), the terms \"we,\" \"us,\" \"our,\"\\n\"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries and affiliates, collectively, unless the context indicates otherwise.\\nOur principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, equipment, accessories and services. NIKE is\\nthe largest seller of athletic footwear and apparel in the world. We sell our products through NIKE Direct operations, which are comprised of both NIKE-owned retail stores\\nand sales through our digital platforms (also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales')]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    return vector_store.similarity_search(query, k=1)\n",
    "\n",
    "\n",
    "retriever.batch(\n",
    "    [\n",
    "        \"How many distribution centers does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='14b2fdd1-9313-477c-ae19-cfa69b0ef99d', metadata={'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'creationdate': '2023-07-20T16:22:00-04:00', 'page_label': '27', 'moddate': '2023-07-20T16:22:08-04:00', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'source': 'nke-10k-2023.pdf', 'start_index': 804, 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'title': '0000320187-23-000039', 'page': 26, 'creator': 'EDGAR Filing HTML Converter', 'keywords': '0000320187-23-000039; ; 10-K', 'total_pages': 107}, page_content='operations. We also lease an office complex in Shanghai, China, our headquarters for our Greater China geography, occupied by employees focused on implementing our\\nwholesale, NIKE Direct and merchandising strategies in the region, among other functions.\\nIn the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of which are owned and three of which are\\nleased. Two other distribution centers, one located in Indianapolis, Indiana and one located in Dayton, Tennessee, are leased and operated by third-party logistics\\nproviders. One distribution center for Converse is located in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States,\\nsome of which are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United States are located in Laakdal,')],\n",
       " [Document(id='ebca5a74-51cd-4253-aaf6-b650c3646f49', metadata={'creator': 'EDGAR Filing HTML Converter', 'keywords': '0000320187-23-000039; ; 10-K', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'page_label': '4', 'source': 'nke-10k-2023.pdf', 'start_index': 0, 'page': 3, 'title': '0000320187-23-000039', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'total_pages': 107, 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'moddate': '2023-07-20T16:22:08-04:00', 'creationdate': '2023-07-20T16:22:00-04:00'}, page_content='Table of Contents\\nPART I\\nITEM 1. BUSINESS\\nGENERAL\\nNIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \"Annual Report\"), the terms \"we,\" \"us,\" \"our,\"\\n\"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries and affiliates, collectively, unless the context indicates otherwise.\\nOur principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, equipment, accessories and services. NIKE is\\nthe largest seller of athletic footwear and apparel in the world. We sell our products through NIKE Direct operations, which are comprised of both NIKE-owned retail stores\\nand sales through our digital platforms (also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales')]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This converts a vector store into a retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "\n",
    "retriever.batch(\n",
    "    [\n",
    "        \"How many distribution centers does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Text into Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --quiet langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login to Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying a pre-build model from Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
    "    aggressiveness: int = Field(\n",
    "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
    "    )\n",
    "    language: str = Field(description=\"The language the text is written in\")\n",
    "\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = llm.with_structured_output(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = structured_llm.invoke(prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having a bit more fine tune over the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "    aggressiveness: int = Field(\n",
    "        ...,\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\").with_structured_output(\n",
    "    Classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='happy', aggressiveness=1, language='spanish')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='sad', aggressiveness=4, language='spanish')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction - Intro to Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging in LangSmith\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"The color of the person's hair if known\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"Height measured in meters\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        # Please see the how-to about improving performance with\n",
    "        # reference examples.\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Alan Smith', hair_color='blond', height_in_meters='1.83')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Alan Smith is 6 feet tall and has blond hair.\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Lists of Entities  --- rather than a single entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"The color of the person's hair if known\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"Height measured in meters\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about people.\"\"\"\n",
    "\n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Jeff', hair_color='black', height_in_meters='1.83'), Person(name='Anna', hair_color='black', height_in_meters=None)])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(schema=Data)\n",
    "text = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Prompting Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"2 🦜 2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"4\"},\n",
    "    {\"role\": \"user\", \"content\": \"2 🦜 3\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"5\"},\n",
    "    {\"role\": \"user\", \"content\": \"3 🦜 4\"},\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using tools - tool texample to messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"The ocean is vast and blue. It's more than 20,000 feet deep.\",\n",
    "        Data(people=[]),\n",
    "    ),\n",
    "    (\n",
    "        \"Fiona traveled far from France to Spain.\",\n",
    "        Data(people=[Person(name=\"Fiona\", height_in_meters=None, hair_color=None)]),\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for txt, tool_call in examples:\n",
    "    if tool_call.people:\n",
    "        # This final message is optional for some providers\n",
    "        ai_response = \"Detected people.\"\n",
    "    else:\n",
    "        ai_response = \"Detected no people.\"\n",
    "    messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The ocean is vast and blue. It's more than 20,000 feet deep.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (c0d836e0-89a3-481c-afda-33d0585f2595)\n",
      " Call ID: c0d836e0-89a3-481c-afda-33d0585f2595\n",
      "  Args:\n",
      "    people: []\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Detected no people.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Fiona traveled far from France to Spain.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (529e93e4-33db-4f50-af6a-03e6b4fc0d4f)\n",
      " Call ID: 529e93e4-33db-4f50-af6a-03e6b4fc0d4f\n",
      "  Args:\n",
      "    people: [{'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Detected people.\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_no_extraction = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"The solar system is large, but earth has only 1 moon.\",\n",
    "}\n",
    "\n",
    "structured_llm = llm.with_structured_output(schema=Data)\n",
    "structured_llm.invoke([message_no_extraction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(messages + [message_no_extraction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loggin with Langsmith\n",
    "\n",
    "# Setup logging in LangSmith\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi Bob! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Be5H3p6KaqecZdGmOiwE6rFF3vt7m', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3cc3aa1e-237f-4b74-ab5f-c96137e3f748-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice it is Memoryless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I don't have access to personal data about users unless it has been shared with me in this conversation. I can't tell your name. If you'd like to share your name or ask about something else, feel free!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 11, 'total_tokens': 57, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Be5HxzHAb6PaCfQIzIxtpRKnj2jNp', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c05024f0-bce5-46da-8d6e-0df36b9aa066-0', usage_metadata={'input_tokens': 11, 'output_tokens': 46, 'total_tokens': 57, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What's my name?\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Passing the entire conversation to the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Bob! How can I help you today, Bob?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 33, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Be5P5lXRoYpcLfyD8l8l6tqIgsJPh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d2647652-66fa-41e1-b71d-375d7ecd3720-0', usage_metadata={'input_tokens': 33, 'output_tokens': 14, 'total_tokens': 47, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "        AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use the libraries to add memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This enables us to support multiple conversation threads with a single application, a common requirement when your application has multiple users'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "''' This enables us to support multiple conversation threads with a single application, a common requirement when your application has multiple users'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Bob! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Bob.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob! How can I help you today, Bob?\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing thread ID resets memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, but I don't have access to personal information about you unless you've shared it in this conversation. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob. If you have any other questions or need assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FOr async support, update the call_model node\n",
    "\n",
    "Update it to be an async function and use .ainvoke when invoking the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, but I don't have access to personal information about you unless you've shared it in the conversation. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# # Async function for node:\n",
    "# async def call_model(state: MessagesState):\n",
    "#     response = await model.ainvoke(state[\"messages\"])\n",
    "#     return {\"messages\": response}\n",
    "\n",
    "\n",
    "# # Define graph as before:\n",
    "# workflow = StateGraph(state_schema=MessagesState)\n",
    "# workflow.add_edge(START, \"model\")\n",
    "# workflow.add_node(\"model\", call_model)\n",
    "# app = workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# # Async invocation:\n",
    "# output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "# output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You talk like a pirate. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ahoy, Jim! Be ye seekin’ treasure or just wishin' fer a bit o’ parley? What can this ol’ sea dog do fer ye today?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Hi! I'm Jim.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yer name be Jim, savvy? A fine name fer a fine matey! What other inquiries can I help ye with, Jim?\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making things slightly more complicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¡Hola, Bob! ¿Cómo puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "query = \"Hi! I'm Bob.\"\n",
    "language = \"Spanish\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Tu nombre es Bob.\n"
     ]
    }
   ],
   "source": [
    "# Notice how state is persistent\n",
    "\n",
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# We didn't have to set \"language\" : language inside app.invoke({ },config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Conversation History\n",
    "\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "\n",
    "Importantly, you will want to do this BEFORE the prompt template but AFTER you load previous messages from Message History."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=85,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\"messages\": trimmed_messages, \"language\": state[\"language\"]}\n",
    "    )\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the conversation won't remember our name since we trimmed out that much history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't know your name. Could you tell me?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"What is my name?\"\n",
    "language = \"English\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it remembers more recent stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You asked what 2 + 2 equals.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc678\"}}\n",
    "query = \"What math problem did I ask?\"\n",
    "language = \"English\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stream the messages back to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Hi| Todd|!| Here|’s| another| joke| for| you|:\n",
      "\n",
      "|Why| don|’t| skeleton|s| fight| each| other|?\n",
      "\n",
      "|They| don|’t| have| the| guts|!||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "query = \"Hi I'm Todd, please tell me a joke.\"\n",
    "language = \"English\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Websearch Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Thursday, March 6, 2025. San Francisco, CA - Weather Forecast', 'url': 'https://weathershogun.com/weather/usa/ca/san-francisco/480/march/2025-03-06', 'content': 'San Francisco, California Weather: Thursday, March 6, 2025. Partly sunny weather with scattered clouds and occasional rain showers.', 'score': 0.94536424}, {'title': 'Weather in San Francisco in March 2025 (California)', 'url': 'https://world-weather.info/forecast/usa/san_francisco/march-2025/', 'content': 'Weather in San Francisco in March 2025 San Francisco Weather Forecast for March 2025 is based on statistical data. March +50° +50° +48° +50° +52° +46° +46° +46° +46° +46° +48° +54° +46° +46° +48° +50° +52° +46° +45° +46° +48° +50° +50° +50° +59° +55° +55° +54° +48° +50° +54° Average weather in March 2025 Extended weather forecast in San Francisco Weather in large and nearby cities Weather in Washington, D.C.+55° Sacramento+82° Pleasanton+73° Redwood City+68° San Leandro+64° San Mateo+64° San Rafael+66° San Ramon+72° South San Francisco+55° Vallejo+68° Palo Alto+72° Pacifica+52° Berkeley+66° Castro Valley+66° Concord+79° Daly City+54° Pleasant Hill+79° Columbia Gardens+64°', 'score': 0.9281033}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "search_results = search.invoke(\"what is the weather in SF\")\n",
    "print(search_results)\n",
    "# If we want, we can create other tools.\n",
    "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_RDdINMXfa3RUiJjspZBB8vTT', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this is not calling the tool yet, it is just telling us to call the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='d924ae6a-2ded-4680-b47c-6e795a44abfc'),\n",
       " AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 83, 'total_tokens': 93, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BeDZZ1mWxMnEivD4bM9ZEbcZN9Lcq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--991e3cd0-e259-4944-bc82-a55bf505cd7e-0', usage_metadata={'input_tokens': 83, 'output_tokens': 10, 'total_tokens': 93, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='whats the weather in sf?', additional_kwargs={}, response_metadata={}, id='8b028eaa-31a7-4701-b7ce-a9ad4e9d3937'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_7TI0mZSf6y0Y9qFoRwzeio6X', 'function': {'arguments': '{\\n  \"query\": \"current weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 88, 'total_tokens': 111, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BeDeBokThtDkL2gDOhnlrA4B7n5sU', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c347e04d-8010-4a9a-94c8-9e76a0c1ff72-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_7TI0mZSf6y0Y9qFoRwzeio6X', 'type': 'tool_call'}], usage_metadata={'input_tokens': 88, 'output_tokens': 23, 'total_tokens': 111, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='[{\"title\": \"Thursday, March 6, 2025. San Francisco, CA - Weather Forecast\", \"url\": \"https://weathershogun.com/weather/usa/ca/san-francisco/480/march/2025-03-06\", \"content\": \"San Francisco, California Weather: Thursday, March 6, 2025. Partly sunny weather with scattered clouds and occasional rain showers.\", \"score\": 0.9245858}, {\"title\": \"March 2025 Weather History in San Francisco California, United ...\", \"url\": \"https://weatherspark.com/h/m/557/2025/3/Historical-Weather-in-March-2025-in-San-Francisco-California-United-States\", \"content\": \"March 2025 Weather History in San Francisco California, United States ; San Francisco Temperature History March 2025 · 40°F · 40°F ; Hourly Temperature in March\", \"score\": 0.7279179}]', name='tavily_search_results_json', id='731278f8-cf58-4141-99b5-fe0ea99333ed', tool_call_id='call_7TI0mZSf6y0Y9qFoRwzeio6X', artifact={'query': 'current weather in San Francisco', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://weathershogun.com/weather/usa/ca/san-francisco/480/march/2025-03-06', 'title': 'Thursday, March 6, 2025. San Francisco, CA - Weather Forecast', 'content': 'San Francisco, California Weather: Thursday, March 6, 2025. Partly sunny weather with scattered clouds and occasional rain showers.', 'score': 0.9245858, 'raw_content': None}, {'url': 'https://weatherspark.com/h/m/557/2025/3/Historical-Weather-in-March-2025-in-San-Francisco-California-United-States', 'title': 'March 2025 Weather History in San Francisco California, United ...', 'content': 'March 2025 Weather History in San Francisco California, United States ; San Francisco Temperature History March 2025 · 40°F · 40°F ; Hourly Temperature in March', 'score': 0.7279179, 'raw_content': None}], 'response_time': 7.5}),\n",
       " AIMessage(content='The current weather in San Francisco is partly sunny with scattered clouds and occasional rain showers.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 329, 'total_tokens': 347, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BeDeLaXer8IONUiHaaiywnFab2SrU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5d558ffc-6ed9-4f27-b9a4-fe7cdc6d7b80-0', usage_metadata={'input_tokens': 329, 'output_tokens': 18, 'total_tokens': 347, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "whats the weather in sf?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_2pZmZOSlhn44Dxa0vv88QMqL)\n",
      " Call ID: call_2pZmZOSlhn44Dxa0vv88QMqL\n",
      "  Args:\n",
      "    query: current weather in San Francisco\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Thursday, March 6, 2025. San Francisco, CA - Weather Forecast\", \"url\": \"https://weathershogun.com/weather/usa/ca/san-francisco/480/march/2025-03-06\", \"content\": \"San Francisco, California Weather: Thursday, March 6, 2025. Partly sunny weather with scattered clouds and occasional rain showers.\", \"score\": 0.9245858}, {\"title\": \"March 2025 Weather History in San Francisco California, United ...\", \"url\": \"https://weatherspark.com/h/m/557/2025/3/Historical-Weather-in-March-2025-in-San-Francisco-California-United-States\", \"content\": \"San Francisco Temperature History March 2025 · 40°F · 40°F ; Hourly Temperature in March 2025 in San Francisco · 12 AM 12 AM ; Cloud Cover in March 2025 in San\", \"score\": 0.7208996}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current weather in San Francisco is partly sunny with scattered clouds and occasional rain showers.\n"
     ]
    }
   ],
   "source": [
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "# Or to stream token level:\n",
    "\n",
    "# for step, metadata in agent_executor.stream(\n",
    "#     {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]},\n",
    "#     stream_mode=\"messages\",\n",
    "# ):\n",
    "#     if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):\n",
    "#         print(text, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Memory to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Hello, Bob! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 85, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BeDh93spQwIIgDcAcQ4a7RnRFLWfJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9055b927-b767-41d1-9b07-d1bfae28dc42-0', usage_metadata={'input_tokens': 85, 'output_tokens': 12, 'total_tokens': 97, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Your name is Bob.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 127, 'total_tokens': 133, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-BeDhLB7KP8luAB42U6eeX2Jidu8by', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a33611eb-6abe-4dee-a432-7ff71458fa56-0', usage_metadata={'input_tokens': 127, 'output_tokens': 6, 'total_tokens': 133, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Part 1\n",
    "\n",
    "\n",
    "This part teaches how to access documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rag Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisit the vector store from part 1\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning Retrival step into a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build them below. Note that we leverage another pre-built LangGraph component, ToolNode, that executes the tool and adds the result as a ToolMessage to the state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile application into a single graph object.\n",
    "\n",
    "Finally, we compile our application into a single graph object. In this case, we are just connecting the steps into a sequence. We also allow the first query_or_respond step to \"short-circuit\" and respond directly to the user if it does not generate a tool call. This allows our application to support conversational experiences-- e.g., responding to generic greetings that may not require a retrieval step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Specify an ID for the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"Can you look up some common ways of doing it?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents w/ RAG and Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
    "\n",
    "input_message = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Many Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDFs...\n",
      "Loading PDF 1/60: [2] INDOOR TESTBED FOR VECTOR FIELD MULTIROBOT ADAPTIVE NAVIGATION (2).pdf\n",
      "Loading PDF 2/60: [33] On_the_Guidance__Navigation_and_Control_of_In_orbit_Space_Robotic_Missions__A_Survey_and_Prospective_Vision.pdf\n",
      "Loading PDF 3/60: [27] Augmented_Kalman_Filter_Design_in_a_Localization_System_Using_Onboard_Sensors_With_Intrinsic_Delays.pdf\n",
      "Loading PDF 4/60: [23] Safe multiagent reinforcement learning.pdf\n",
      "Loading PDF 5/60: [57] Matroid s10514-018-9778-6.pdf\n",
      "Loading PDF 6/60: [13] Multi-Robot_Dynamical_Source_Seeking_in_Unknown_Environments.pdf\n",
      "Loading PDF 7/60: [44] Fully_Decentralized_Controller_for_Multi-Robot_Collective_Transport_in_Space_Applications.pdf\n",
      "Loading PDF 8/60: [58] Differential_analysis_of_bifurcations_and_isolated_singularities_for_robots_and_mechanisms.pdf\n",
      "Loading PDF 9/60: [22] Mobile_Robot_Navigation_Functions_Tuned_by_Sensor_Readings_in_Partially_Known_Environments.pdf\n",
      "Loading PDF 10/60: [40] An_Autonomous_Navigation_Strategy_Based_on_Improved_Hector_SLAM_With_Dynamic_Weighted_A_Algorithm.pdf\n",
      "Loading PDF 11/60: [53] Oracle Complexity arjevani17a.pdf\n",
      "Loading PDF 12/60: [20] Near-Optimal_Multi-Robot_Motion_Planning_with_Finite_Sampling.pdf\n",
      "Loading PDF 13/60: [47] zeroth order complexity 2406.19617v1.pdf\n",
      "Loading PDF 14/60: [45] An_Approach_to_Formulate_the_Hessian_Matrix_for_Dynamic_Control_of_Parallel_Robots.pdf\n",
      "Loading PDF 15/60: [35] A_gradient_method_for_realtime_robot_control.pdf\n",
      "Loading PDF 16/60: [39] Collective Transport.pdf\n",
      "Loading PDF 17/60: [31] infotaxis - nature05464.pdf\n",
      "Loading PDF 18/60: [46] jets.pdf\n",
      "Loading PDF 19/60: [36] Consistent unscented incremental smoothing.pdf\n",
      "Loading PDF 20/60: [6] Spontaneous-Ordering_Platoon_Control_for_Multirobot_Path_Navigation_Using_Guiding_Vector_Fields.pdf\n",
      "Loading PDF 21/60: [19] Distributed_Sampling-Based_Model_Predictive_Control_via_Belief_Propagation_for_Multi-Robot_Formation_Navigation.pdf\n",
      "Loading PDF 22/60: [41] Modified_Newtons_method_applied_to_potential_field-based_navigation_for_mobile_robots.pdf\n",
      "Loading PDF 23/60: [52] Sparsity_Structure_and_Optimality_of_Multi-Robot_Coverage_Control.pdf\n",
      "Loading PDF 24/60: [55] ZO-JADE_Zeroth-Order_Curvature-Aware_Distributed_Multi-Agent_Convex_Optimization.pdf\n",
      "Loading PDF 25/60: [8] Distributed_coordinated_path_following_using_guiding_vector_fields.pdf\n",
      "Loading PDF 26/60: [29] Multi-Robot_Collaborative_Source_Searching_Strategy_in_Large-Scale_Chemical_Clusters.pdf\n",
      "Loading PDF 27/60: [21] Distributed_Algorithms_via_Saddle-Point_Dynamics_for_Multi-Robot_Task_Assignment.pdf\n",
      "Loading PDF 28/60: [25] Motion_Planning_of_3D_Nonholonomic_Robots_via_Curvature-Constrained_Vector_Fields.pdf\n",
      "Loading PDF 29/60: [16] Fast and Flexible multiagent decisionmaking.pdf\n",
      "Loading PDF 30/60: [26] Multi-Agent_Active_Search_A_Reinforcement_Learning_Approach.pdf\n",
      "Loading PDF 31/60: [17] Control_of_Agreement_and_Disagreement_Cascades_with_Distributed_Inputs.pdf\n",
      "Loading PDF 32/60: [59] Numerical_Study_of_Some_Intelligent_Robot_Systems_Governed_by_the_Fractional_Differential_Equations.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 44 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 57 0 (offset 0)\n",
      "Ignoring wrong pointing object 77 0 (offset 0)\n",
      "Ignoring wrong pointing object 79 0 (offset 0)\n",
      "Ignoring wrong pointing object 95 0 (offset 0)\n",
      "Ignoring wrong pointing object 101 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF 33/60: [30] Final Paper.pdf\n",
      "Loading PDF 34/60: [7] Guiding_Vector_Fields_for_the_Distributed_Motion_Coordination_of_Mobile_Robots.pdf\n",
      "Loading PDF 35/60: [14] A Survey of Distributed Relative Localization Algorithms.pdf\n",
      "Loading PDF 36/60: [51] Optimizing_Topologies_for_Probabilistically_Secure_Multi-Robot_Systems.pdf\n",
      "Loading PDF 37/60: [3] Initial_Study_of_Multirobot_Adaptive_Navigation_for_Exploring_Environmental_Vector_Fields.pdf\n",
      "Loading PDF 38/60: [24] Simultaneous_Position_and_Orientation_Planning_of_Nonholonomic_Multirobot_Systems_A_Dynamic_Vector_Field_Approach.pdf\n",
      "Loading PDF 39/60: [37] Distributed_Nonlinear_Trajectory_Optimization_for_Multi-Robot_Motion_Planning.pdf\n",
      "Loading PDF 40/60: [12] A_Distributed_Multi-Robot_Framework_for_Exploration_Information_Acquisition_and_Consensus.pdf\n",
      "Loading PDF 41/60: [28] Highly_Efficient_Observation_Process_Based_on_FFT_Filtering_for_Robot_Swarm_Collaborative_Navigation_in_Unknown_Environments.pdf\n",
      "Loading PDF 42/60: [5] Structured_Isosurface_Mapping_of_3-D_Scalar_Fields_While_Seeking_Extremum_With_Mobile_Sensor_Networks.pdf\n",
      "Loading PDF 43/60: [34] Vector Field Driven984752.pdf\n",
      "Loading PDF 44/60: [1] Dynamic_Control_of_Mobile_Multirobot_Systems_The_Cluster_Space_Formulation.pdf\n",
      "Loading PDF 45/60: [56] zeroth order saddle points10208-021-09499-8.pdf\n",
      "Loading PDF 46/60: [11] UAV Automatica mobile.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 141 0 (offset 0)\n",
      "Ignoring wrong pointing object 249 0 (offset 0)\n",
      "Ignoring wrong pointing object 280 0 (offset 0)\n",
      "Ignoring wrong pointing object 293 0 (offset 0)\n",
      "Ignoring wrong pointing object 300 0 (offset 0)\n",
      "Ignoring wrong pointing object 391 0 (offset 0)\n",
      "Ignoring wrong pointing object 416 0 (offset 0)\n",
      "Ignoring wrong pointing object 531 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF 47/60: [49] NeurIPS-2019-necessary-and-sufficient-geometries-for-gradient-methods-Paper.pdf\n",
      "Loading PDF 48/60: [54] Multirobot_Symmetric_Formations_for_Gradient_and_Hessian_Estimation_With_Application_to_Source_Seeking.pdf\n",
      "Loading PDF 49/60: [48] Importance Sampling1608.08814v1.pdf\n",
      "Loading PDF 50/60: [60] swarm intelligence a review.pdf\n",
      "Loading PDF 51/60: [32] khatib-1986-real-time-obstacle-avoidance-for-manipulators-and-mobile-robots.pdf\n",
      "Loading PDF 52/60: [15] Distributing_Collaborative_Multi-Robot_Planning_With_Gaussian_Belief_Propagation.pdf\n",
      "Loading PDF 53/60: [43] partial eigenstructure math-06-10-647.pdf\n",
      "Loading PDF 54/60: [9] Multirobot_Field_of_View_Control_With_Adaptive_Decentralization.pdf\n",
      "Loading PDF 55/60: [38] Distributed_Competition_of_Multi-Robot_Coordination_Under_Variable_and_Switching_Topologies.pdf\n",
      "Loading PDF 56/60: [18] A survey of distributed optimization methods.pdf\n",
      "Loading PDF 57/60: [50] 2402.11858v5.pdf\n",
      "Loading PDF 58/60: [10] Singularity-Free_Guiding_Vector_Field_for_Robot_Navigation.pdf\n",
      "Loading PDF 59/60: [42] Output_Tracking_Control_of_a_Nonlinear_System_Based_on_Takagi-Sugeno_Fuzzy_Model_Generalized_Partial_Eigenstructure_Assignment_Approach.pdf\n",
      "Loading PDF 60/60: [4] Dual_Quaternion-Based_Control_for_Dynamic_Robot_Formations.pdf\n",
      "Successfully loaded 60 papers\n",
      "\n",
      "=== Processing paper 1/60: [2] INDOOR TESTBED FOR VECTOR FIELD MULTIROBOT ADAPTIVE NAVIGATION (2).pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [2] INDOOR TESTBED FOR VECTOR FIELD MULTIROBOT ADAPTIVE NAVIGATION (2).pdf\n",
      "\n",
      "=== Processing paper 2/60: [33] On_the_Guidance__Navigation_and_Control_of_In_orbit_Space_Robotic_Missions__A_Survey_and_Prospective_Vision.pdf ===\n",
      "Warning: [33] On_the_Guidance__Navigation_and_Control_of_In_orbit_Space_Robotic_Missions__A_Survey_and_Prospective_Vision.pdf is very long (235585 chars). Consider splitting.\n",
      "Sending to LLM...\n",
      "✗ Error analyzing [33] On_the_Guidance__Navigation_and_Control_of_In_orbit_Space_Robotic_Missions__A_Survey_and_Prospective_Vision.pdf: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-IdoetvceX7sZxqyeq36dumvF on tokens per min (TPM): Limit 30000, Requested 61013. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "=== Processing paper 3/60: [27] Augmented_Kalman_Filter_Design_in_a_Localization_System_Using_Onboard_Sensors_With_Intrinsic_Delays.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [27] Augmented_Kalman_Filter_Design_in_a_Localization_System_Using_Onboard_Sensors_With_Intrinsic_Delays.pdf\n",
      "\n",
      "=== Processing paper 4/60: [23] Safe multiagent reinforcement learning.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [23] Safe multiagent reinforcement learning.pdf\n",
      "\n",
      "=== Processing paper 5/60: [57] Matroid s10514-018-9778-6.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [57] Matroid s10514-018-9778-6.pdf\n",
      "\n",
      "=== Processing paper 6/60: [13] Multi-Robot_Dynamical_Source_Seeking_in_Unknown_Environments.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [13] Multi-Robot_Dynamical_Source_Seeking_in_Unknown_Environments.pdf\n",
      "\n",
      "=== Processing paper 7/60: [44] Fully_Decentralized_Controller_for_Multi-Robot_Collective_Transport_in_Space_Applications.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [44] Fully_Decentralized_Controller_for_Multi-Robot_Collective_Transport_in_Space_Applications.pdf\n",
      "\n",
      "=== Processing paper 8/60: [58] Differential_analysis_of_bifurcations_and_isolated_singularities_for_robots_and_mechanisms.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [58] Differential_analysis_of_bifurcations_and_isolated_singularities_for_robots_and_mechanisms.pdf\n",
      "\n",
      "=== Processing paper 9/60: [22] Mobile_Robot_Navigation_Functions_Tuned_by_Sensor_Readings_in_Partially_Known_Environments.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [22] Mobile_Robot_Navigation_Functions_Tuned_by_Sensor_Readings_in_Partially_Known_Environments.pdf\n",
      "\n",
      "=== Processing paper 10/60: [40] An_Autonomous_Navigation_Strategy_Based_on_Improved_Hector_SLAM_With_Dynamic_Weighted_A_Algorithm.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [40] An_Autonomous_Navigation_Strategy_Based_on_Improved_Hector_SLAM_With_Dynamic_Weighted_A_Algorithm.pdf\n",
      "\n",
      "=== Processing paper 11/60: [53] Oracle Complexity arjevani17a.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [53] Oracle Complexity arjevani17a.pdf\n",
      "\n",
      "=== Processing paper 12/60: [20] Near-Optimal_Multi-Robot_Motion_Planning_with_Finite_Sampling.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [20] Near-Optimal_Multi-Robot_Motion_Planning_with_Finite_Sampling.pdf\n",
      "\n",
      "=== Processing paper 13/60: [47] zeroth order complexity 2406.19617v1.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [47] zeroth order complexity 2406.19617v1.pdf\n",
      "\n",
      "=== Processing paper 14/60: [45] An_Approach_to_Formulate_the_Hessian_Matrix_for_Dynamic_Control_of_Parallel_Robots.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [45] An_Approach_to_Formulate_the_Hessian_Matrix_for_Dynamic_Control_of_Parallel_Robots.pdf\n",
      "\n",
      "=== Processing paper 15/60: [35] A_gradient_method_for_realtime_robot_control.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [35] A_gradient_method_for_realtime_robot_control.pdf\n",
      "\n",
      "=== Processing paper 16/60: [39] Collective Transport.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [39] Collective Transport.pdf\n",
      "\n",
      "=== Processing paper 17/60: [31] infotaxis - nature05464.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [31] infotaxis - nature05464.pdf\n",
      "\n",
      "=== Processing paper 18/60: [46] jets.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [46] jets.pdf\n",
      "\n",
      "=== Processing paper 19/60: [36] Consistent unscented incremental smoothing.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [36] Consistent unscented incremental smoothing.pdf\n",
      "\n",
      "=== Processing paper 20/60: [6] Spontaneous-Ordering_Platoon_Control_for_Multirobot_Path_Navigation_Using_Guiding_Vector_Fields.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [6] Spontaneous-Ordering_Platoon_Control_for_Multirobot_Path_Navigation_Using_Guiding_Vector_Fields.pdf\n",
      "\n",
      "=== Processing paper 21/60: [19] Distributed_Sampling-Based_Model_Predictive_Control_via_Belief_Propagation_for_Multi-Robot_Formation_Navigation.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [19] Distributed_Sampling-Based_Model_Predictive_Control_via_Belief_Propagation_for_Multi-Robot_Formation_Navigation.pdf\n",
      "\n",
      "=== Processing paper 22/60: [41] Modified_Newtons_method_applied_to_potential_field-based_navigation_for_mobile_robots.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [41] Modified_Newtons_method_applied_to_potential_field-based_navigation_for_mobile_robots.pdf\n",
      "\n",
      "=== Processing paper 23/60: [52] Sparsity_Structure_and_Optimality_of_Multi-Robot_Coverage_Control.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [52] Sparsity_Structure_and_Optimality_of_Multi-Robot_Coverage_Control.pdf\n",
      "\n",
      "=== Processing paper 24/60: [55] ZO-JADE_Zeroth-Order_Curvature-Aware_Distributed_Multi-Agent_Convex_Optimization.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [55] ZO-JADE_Zeroth-Order_Curvature-Aware_Distributed_Multi-Agent_Convex_Optimization.pdf\n",
      "\n",
      "=== Processing paper 25/60: [8] Distributed_coordinated_path_following_using_guiding_vector_fields.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [8] Distributed_coordinated_path_following_using_guiding_vector_fields.pdf\n",
      "\n",
      "=== Processing paper 26/60: [29] Multi-Robot_Collaborative_Source_Searching_Strategy_in_Large-Scale_Chemical_Clusters.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [29] Multi-Robot_Collaborative_Source_Searching_Strategy_in_Large-Scale_Chemical_Clusters.pdf\n",
      "\n",
      "=== Processing paper 27/60: [21] Distributed_Algorithms_via_Saddle-Point_Dynamics_for_Multi-Robot_Task_Assignment.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [21] Distributed_Algorithms_via_Saddle-Point_Dynamics_for_Multi-Robot_Task_Assignment.pdf\n",
      "\n",
      "=== Processing paper 28/60: [25] Motion_Planning_of_3D_Nonholonomic_Robots_via_Curvature-Constrained_Vector_Fields.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [25] Motion_Planning_of_3D_Nonholonomic_Robots_via_Curvature-Constrained_Vector_Fields.pdf\n",
      "\n",
      "=== Processing paper 29/60: [16] Fast and Flexible multiagent decisionmaking.pdf ===\n",
      "Warning: [16] Fast and Flexible multiagent decisionmaking.pdf is very long (104146 chars). Consider splitting.\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [16] Fast and Flexible multiagent decisionmaking.pdf\n",
      "\n",
      "=== Processing paper 30/60: [26] Multi-Agent_Active_Search_A_Reinforcement_Learning_Approach.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [26] Multi-Agent_Active_Search_A_Reinforcement_Learning_Approach.pdf\n",
      "\n",
      "=== Processing paper 31/60: [17] Control_of_Agreement_and_Disagreement_Cascades_with_Distributed_Inputs.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [17] Control_of_Agreement_and_Disagreement_Cascades_with_Distributed_Inputs.pdf\n",
      "\n",
      "=== Processing paper 32/60: [59] Numerical_Study_of_Some_Intelligent_Robot_Systems_Governed_by_the_Fractional_Differential_Equations.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [59] Numerical_Study_of_Some_Intelligent_Robot_Systems_Governed_by_the_Fractional_Differential_Equations.pdf\n",
      "\n",
      "=== Processing paper 33/60: [30] Final Paper.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [30] Final Paper.pdf\n",
      "\n",
      "=== Processing paper 34/60: [7] Guiding_Vector_Fields_for_the_Distributed_Motion_Coordination_of_Mobile_Robots.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [7] Guiding_Vector_Fields_for_the_Distributed_Motion_Coordination_of_Mobile_Robots.pdf\n",
      "\n",
      "=== Processing paper 35/60: [14] A Survey of Distributed Relative Localization Algorithms.pdf ===\n",
      "Warning: [14] A Survey of Distributed Relative Localization Algorithms.pdf is very long (109213 chars). Consider splitting.\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [14] A Survey of Distributed Relative Localization Algorithms.pdf\n",
      "\n",
      "=== Processing paper 36/60: [51] Optimizing_Topologies_for_Probabilistically_Secure_Multi-Robot_Systems.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [51] Optimizing_Topologies_for_Probabilistically_Secure_Multi-Robot_Systems.pdf\n",
      "\n",
      "=== Processing paper 37/60: [3] Initial_Study_of_Multirobot_Adaptive_Navigation_for_Exploring_Environmental_Vector_Fields.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [3] Initial_Study_of_Multirobot_Adaptive_Navigation_for_Exploring_Environmental_Vector_Fields.pdf\n",
      "\n",
      "=== Processing paper 38/60: [24] Simultaneous_Position_and_Orientation_Planning_of_Nonholonomic_Multirobot_Systems_A_Dynamic_Vector_Field_Approach.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [24] Simultaneous_Position_and_Orientation_Planning_of_Nonholonomic_Multirobot_Systems_A_Dynamic_Vector_Field_Approach.pdf\n",
      "\n",
      "=== Processing paper 39/60: [37] Distributed_Nonlinear_Trajectory_Optimization_for_Multi-Robot_Motion_Planning.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [37] Distributed_Nonlinear_Trajectory_Optimization_for_Multi-Robot_Motion_Planning.pdf\n",
      "\n",
      "=== Processing paper 40/60: [12] A_Distributed_Multi-Robot_Framework_for_Exploration_Information_Acquisition_and_Consensus.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [12] A_Distributed_Multi-Robot_Framework_for_Exploration_Information_Acquisition_and_Consensus.pdf\n",
      "\n",
      "=== Processing paper 41/60: [28] Highly_Efficient_Observation_Process_Based_on_FFT_Filtering_for_Robot_Swarm_Collaborative_Navigation_in_Unknown_Environments.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [28] Highly_Efficient_Observation_Process_Based_on_FFT_Filtering_for_Robot_Swarm_Collaborative_Navigation_in_Unknown_Environments.pdf\n",
      "\n",
      "=== Processing paper 42/60: [5] Structured_Isosurface_Mapping_of_3-D_Scalar_Fields_While_Seeking_Extremum_With_Mobile_Sensor_Networks.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [5] Structured_Isosurface_Mapping_of_3-D_Scalar_Fields_While_Seeking_Extremum_With_Mobile_Sensor_Networks.pdf\n",
      "\n",
      "=== Processing paper 43/60: [34] Vector Field Driven984752.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [34] Vector Field Driven984752.pdf\n",
      "\n",
      "=== Processing paper 44/60: [1] Dynamic_Control_of_Mobile_Multirobot_Systems_The_Cluster_Space_Formulation.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [1] Dynamic_Control_of_Mobile_Multirobot_Systems_The_Cluster_Space_Formulation.pdf\n",
      "\n",
      "=== Processing paper 45/60: [56] zeroth order saddle points10208-021-09499-8.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [56] zeroth order saddle points10208-021-09499-8.pdf\n",
      "\n",
      "=== Processing paper 46/60: [11] UAV Automatica mobile.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [11] UAV Automatica mobile.pdf\n",
      "\n",
      "=== Processing paper 47/60: [49] NeurIPS-2019-necessary-and-sufficient-geometries-for-gradient-methods-Paper.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [49] NeurIPS-2019-necessary-and-sufficient-geometries-for-gradient-methods-Paper.pdf\n",
      "\n",
      "=== Processing paper 48/60: [54] Multirobot_Symmetric_Formations_for_Gradient_and_Hessian_Estimation_With_Application_to_Source_Seeking.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [54] Multirobot_Symmetric_Formations_for_Gradient_and_Hessian_Estimation_With_Application_to_Source_Seeking.pdf\n",
      "\n",
      "=== Processing paper 49/60: [48] Importance Sampling1608.08814v1.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [48] Importance Sampling1608.08814v1.pdf\n",
      "\n",
      "=== Processing paper 50/60: [60] swarm intelligence a review.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [60] swarm intelligence a review.pdf\n",
      "\n",
      "=== Processing paper 51/60: [32] khatib-1986-real-time-obstacle-avoidance-for-manipulators-and-mobile-robots.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [32] khatib-1986-real-time-obstacle-avoidance-for-manipulators-and-mobile-robots.pdf\n",
      "\n",
      "=== Processing paper 52/60: [15] Distributing_Collaborative_Multi-Robot_Planning_With_Gaussian_Belief_Propagation.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [15] Distributing_Collaborative_Multi-Robot_Planning_With_Gaussian_Belief_Propagation.pdf\n",
      "\n",
      "=== Processing paper 53/60: [43] partial eigenstructure math-06-10-647.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [43] partial eigenstructure math-06-10-647.pdf\n",
      "\n",
      "=== Processing paper 54/60: [9] Multirobot_Field_of_View_Control_With_Adaptive_Decentralization.pdf ===\n",
      "Warning: [9] Multirobot_Field_of_View_Control_With_Adaptive_Decentralization.pdf is very long (107946 chars). Consider splitting.\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [9] Multirobot_Field_of_View_Control_With_Adaptive_Decentralization.pdf\n",
      "\n",
      "=== Processing paper 55/60: [38] Distributed_Competition_of_Multi-Robot_Coordination_Under_Variable_and_Switching_Topologies.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [38] Distributed_Competition_of_Multi-Robot_Coordination_Under_Variable_and_Switching_Topologies.pdf\n",
      "\n",
      "=== Processing paper 56/60: [18] A survey of distributed optimization methods.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [18] A survey of distributed optimization methods.pdf\n",
      "\n",
      "=== Processing paper 57/60: [50] 2402.11858v5.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [50] 2402.11858v5.pdf\n",
      "\n",
      "=== Processing paper 58/60: [10] Singularity-Free_Guiding_Vector_Field_for_Robot_Navigation.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [10] Singularity-Free_Guiding_Vector_Field_for_Robot_Navigation.pdf\n",
      "\n",
      "=== Processing paper 59/60: [42] Output_Tracking_Control_of_a_Nonlinear_System_Based_on_Takagi-Sugeno_Fuzzy_Model_Generalized_Partial_Eigenstructure_Assignment_Approach.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [42] Output_Tracking_Control_of_a_Nonlinear_System_Based_on_Takagi-Sugeno_Fuzzy_Model_Generalized_Partial_Eigenstructure_Assignment_Approach.pdf\n",
      "\n",
      "=== Processing paper 60/60: [4] Dual_Quaternion-Based_Control_for_Dynamic_Robot_Formations.pdf ===\n",
      "Sending to LLM...\n",
      "✓ Successfully analyzed [4] Dual_Quaternion-Based_Control_for_Dynamic_Robot_Formations.pdf\n",
      "\n",
      "Writing results to all_paper_summaries.md...\n",
      "✓ Analysis complete! Results saved to all_paper_summaries.md\n"
     ]
    }
   ],
   "source": [
    "# Import Relevant Libraries\n",
    "import getpass\n",
    "import os\n",
    "import glob\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader  # Added missing import\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Suppress PDF parsing warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Keys for tracing and API\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter LangSmith API Key: \")\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "def load_pdfs_from_folder(folder):\n",
    "    \"\"\"Load PDFs and return each as a separate document without combining pages\"\"\"\n",
    "    pdf_paths = glob.glob(f\"{folder}/*.pdf\")\n",
    "    docs = []\n",
    "    for i, path in enumerate(pdf_paths):\n",
    "        print(f\"Loading PDF {i+1}/{len(pdf_paths)}: {os.path.basename(path)}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(path)\n",
    "            pdf_docs = loader.load()\n",
    "            \n",
    "            # Keep each page separate to avoid context window issues\n",
    "            # But combine into logical chunks if needed\n",
    "            full_text = \"\"\n",
    "            for page in pdf_docs:\n",
    "                full_text += page.page_content + \"\\n\"\n",
    "            \n",
    "            # Only add if we successfully extracted text\n",
    "            if full_text.strip():\n",
    "                docs.append({\n",
    "                    \"path\": path, \n",
    "                    \"content\": full_text,\n",
    "                    \"filename\": os.path.basename(path)\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Warning: No text extracted from {path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return docs\n",
    "\n",
    "# Field description\n",
    "# Field description\n",
    "MY_FIELD_DESCRIPTION = \"\"\"My field is Multirobot Adaptive Navigation in Environmental Vector Fields, \n",
    "combining robotics, differential geometry, and information theory to determine the absolute minimum \n",
    "information required for navigation in complex environments. The core discovery is that environmental \n",
    "vector fields contain sufficient geometric structure for complete navigation using only instantaneous \n",
    "measurements from 3 or 4 strategically positioned robots, which can extract all necessary second-order field \n",
    "information (gradients, Jacobians, Hessians, eigenstructure) that traditionally required 6 or more \n",
    "measurements. The key breakthrough is developing memory-free control laws that achieve convergence using \n",
    "only instantaneous 10Hz measurements without any state estimation or feedback history, exploiting \n",
    "fundamental mathematical properties like Hessian symmetry and vector field consistency constraints where \n",
    "the field structure itself acts as a natural computer providing navigation instructions through classical \n",
    "optimization geometry. Technical innovations include proving that 4-point multi-robot formations form sufficient \n",
    "sampling stencils for second-order field properties, creating universal navigation primitives that handle \n",
    "saddle points in sclar fieldss, three robot primitives that can attract, repel, and maintain a fixed orbit around\n",
    "critical points in 2D vector fields (focus, nodes, centers, vortices, saddle points) through a single memoryless orbit primitive, and \n",
    "achieving sub-centimeter formation precision enabling reliable field geometry extraction.\n",
    "Another contribution is a primitive that moves through a vector field along the separatrix or bifurcation. This approach \n",
    "enables applications in GPS-denied environments like ocean robots tracking pollution plumes with minimal \n",
    "battery power, aerial swarms characterizing atmospheric phenomena with limited communication, and \n",
    "search-and-rescue teams following chemical gradients, with all theoretical results validated on a \n",
    "physical testbed marking the first successful implementation of truly information-minimal navigation \n",
    "bridging the simulation-to-reality gap.\"\"\"\n",
    "\n",
    "# Analysis questions\n",
    "ANALYSIS_QUESTIONS = \"\"\"\n",
    "Analyze this paper and extract the following information:\n",
    "\n",
    "1. Main Contributions: What are the 2-4 key contributions claimed by the authors?\n",
    "2. Objective: What was their objective, and how well did they achive it (Give metrics)\n",
    "3. Limitations: What limitations did the identify to their work (Identify 2-5)\n",
    "4. Future Work: What future directions do they see their work going in (Identify 2 -5)\n",
    "5. Methods: What hardware and software were used? Was it open source or custom.\n",
    "6. Field Positiong: How do the authors describe the current state of their own field? Be very verbose here (like 100 words)\n",
    "7. Multirobot fields: How do the authors describe the current state of the art in multirobot or multiagent systems? Very verbose again.\n",
    "8. Research Gaps: Does the author identify any outstanding challenges in their field, or areas that are not explored well.\n",
    "9. Related Work Section: What other papers do they cite as most relevant? (note ~10 key references) Copy these citations exactly.\n",
    "10. Jacobians and Hessians: Does it estimate a Jacobian or Hessian from Distributed measurements? If so, how?\n",
    "10. Physical Implementation: Is it all in sim, or do they have some real world testing also? If so, how?\n",
    "11. Vector Fields: Does this work pertain to environmental vector fields, or to Artificial vector fields?\n",
    "12. Novelty and Elegance: Do any of these papers use similar techniques as my approach, solve the same problem I'm addressing in a different method, makes a claim that would encompass my work?\n",
    "13. Adaptive and Reactive: Is the approach reactive using only current readings, or does it need multiple readings (like slam?).\n",
    "14. Memory requirements: Does this paper require memory or state history for navigation decisions, and if so, what specific information must be stored between time steps? If control is involved, does it mention discrete steps or continous control laws?\n",
    "15. What branches of mathematics are being used? \n",
    "16. Formation Control: What formation is required or achieved, and how does formation accuracy affect robots?\n",
    "17. Scalability: Does the paper address scalability? Does it address the minimum amount of information needed to achieve success?\n",
    "18. Practicality and Usability: Are there any practical examples for the research?\n",
    "19. Fail Methods: Does the method degrade gracefully when formation is lost or robots drift from prescribed positions? What about if robots fail in communication?\n",
    "20. Key words: Does it mention any of these key words, if so, in what context? Focii, saddle, centre, vortex, sink, source, separatrix, bifurcation, memoryless navigation, eigenvector, eigenvalue, reactive navigation, adapative navigation, eigenstructure, determinant.\n",
    "21. Relevance: on a scale from 1-10, how relevant is this to my research? Explain your reasoning.\n",
    "22. Similiarities and differences. Explain how my research addresses any gaps or future work identified in the paper. (or n/a and explanation.)\n",
    "\n",
    "\n",
    "Please be specific and quote directly when the authors make important claims about the field or gaps. Be verbose, as I want to extract as much context as possible out of each paper as it related to my field as possible.\n",
    "\"\"\"\n",
    "\n",
    "# Create the review prompt\n",
    "review_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a highly analytical academic reviewer.\\nUser's field: \" + MY_FIELD_DESCRIPTION),\n",
    "    (\"human\", \"Given the following paper text, answer these questions:\\n\"\n",
    "     + ANALYSIS_QUESTIONS +\n",
    "    \"\\n=== BEGIN PAPER DOCUMENT ===\\n{paper_text}\\n=== END PAPER DOCUMENT ===\")\n",
    "])\n",
    "\n",
    "def analyze_papers(folder_path=\"./PapersForResearch\", output_file=\"all_paper_summaries.md\"):\n",
    "    \"\"\"Main function to analyze all papers and generate summaries\"\"\"\n",
    "    \n",
    "    # Load PDFs\n",
    "    print(\"Loading PDFs...\")\n",
    "    pdf_docs = load_pdfs_from_folder(folder_path)\n",
    "    print(f\"Successfully loaded {len(pdf_docs)} papers\")\n",
    "    \n",
    "    if not pdf_docs:\n",
    "        print(\"No PDFs found or loaded successfully!\")\n",
    "        return\n",
    "    \n",
    "    # Process each paper\n",
    "    results = []\n",
    "    \n",
    "    for i, doc in enumerate(pdf_docs):\n",
    "        print(f\"\\n=== Processing paper {i+1}/{len(pdf_docs)}: {doc['filename']} ===\")\n",
    "        \n",
    "        # Check if content is too long (rough estimate for token limit)\n",
    "        if len(doc['content']) > 100000:  # Adjust this threshold as needed\n",
    "            print(f\"Warning: {doc['filename']} is very long ({len(doc['content'])} chars). Consider splitting.\")\n",
    "        \n",
    "        # Prepare input\n",
    "        paper_input = {\"paper_text\": doc['content']}\n",
    "        \n",
    "        # Create chain\n",
    "        chain = review_prompt | llm\n",
    "        \n",
    "        # Generate analysis\n",
    "        try:\n",
    "            print(f\"Sending to LLM...\")\n",
    "            response = chain.invoke(paper_input)\n",
    "            summary = response.content if hasattr(response, 'content') else str(response)\n",
    "            print(f\"✓ Successfully analyzed {doc['filename']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            summary = f\"ERROR analyzing {doc['filename']}: {e}\"\n",
    "            print(f\"✗ Error analyzing {doc['filename']}: {e}\")\n",
    "        \n",
    "        # Store result\n",
    "        results.append({\n",
    "            \"file\": doc[\"path\"],\n",
    "            \"filename\": doc[\"filename\"],\n",
    "            \"summary\": summary,\n",
    "        })\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(2)  # Adjust based on your OpenAI plan\n",
    "    \n",
    "    # Write all results to file (FIXED: moved outside the loop)\n",
    "    print(f\"\\nWriting results to {output_file}...\")\n",
    "    with open(output_file, \"w\", encoding='utf-8') as f:\n",
    "        f.write(f\"# Academic Paper Analysis Results\\n\\n\")\n",
    "        f.write(f\"Generated on: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        f.write(f\"Total papers analyzed: {len(results)}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        \n",
    "        for r in results:\n",
    "            f.write(f\"# Analysis for {r['filename']}\\n\\n\")\n",
    "            f.write(f\"**File Path:** {r['file']}\\n\\n\")\n",
    "            f.write(r['summary'])\n",
    "            f.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    print(f\"✓ Analysis complete! Results saved to {output_file}\")\n",
    "    return results\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # You can customize these parameters\n",
    "    results = analyze_papers(\n",
    "        folder_path=\"./PapersForResearch\",  # Change this to your PDF folder\n",
    "        output_file=\"all_paper_summaries.md\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive literature meta-analysis...\n",
      "COMPREHENSIVE LITERATURE META-ANALYSIS\n",
      "============================================================\n",
      "Loaded 30 paper summaries\n",
      "=== FIELD EVOLUTION ANALYSIS ===\n",
      "Papers with identifiable years: 0/30\n",
      "\n",
      "=== RESEARCH TAXONOMY ===\n",
      "\n",
      "1. PRIMARY RESEARCH THEMES:\n",
      "   • Navigation & Control: 30 papers (100.0%)\n",
      "   • Vector Fields: 30 papers (100.0%)\n",
      "   • Environmental Sensing: 30 papers (100.0%)\n",
      "   • Adaptive Systems: 30 papers (100.0%)\n",
      "   • Localization: 30 papers (100.0%)\n",
      "   • Multi-Robot Systems: 29 papers (96.7%)\n",
      "   • Formation Control: 28 papers (93.3%)\n",
      "   • Source Seeking: 4 papers (13.3%)\n",
      "\n",
      "2. METHODOLOGICAL APPROACHES:\n",
      "   • Real-world Testing: 30 papers (100.0%)\n",
      "   • Simulation: 28 papers (93.3%)\n",
      "   • Graph Theory: 16 papers (53.3%)\n",
      "   • Lyapunov Methods: 15 papers (50.0%)\n",
      "   • Optimization: 14 papers (46.7%)\n",
      "   • Game Theory: 6 papers (20.0%)\n",
      "   • Kalman Filtering: 3 papers (10.0%)\n",
      "   • Machine Learning: 3 papers (10.0%)\n",
      "\n",
      "=== COMMONLY MENTIONED RESEARCH GAPS ===\n",
      "\n",
      "Most frequently mentioned challenges/gaps:\n",
      "   • 'vector': 134 mentions\n",
      "   • 'distributed': 117 mentions\n",
      "   • 'authors': 108 mentions\n",
      "   • 'navigation': 95 mentions\n",
      "   • 'adaptive': 86 mentions\n",
      "   • 'which': 85 mentions\n",
      "   • 'paper': 84 mentions\n",
      "   • 'positioning': 81 mentions\n",
      "   • '**field': 72 mentions\n",
      "   • 'field': 70 mentions\n",
      "   • 'algorithms': 67 mentions\n",
      "   • 'multirobot': 66 mentions\n",
      "   • 'their': 65 mentions\n",
      "   • 'control': 65 mentions\n",
      "   • 'challenges': 64 mentions\n",
      "\n",
      "✓ Comprehensive report saved to: literature_meta_analysis_report.md\n",
      "\n",
      "Generating AI-powered research positioning analysis...\n",
      "\n",
      "================================================================================\n",
      "RESEARCH POSITIONING ANALYSIS\n",
      "================================================================================\n",
      "To provide a comprehensive research positioning analysis for your work on multirobot adaptive navigation in environmental vector fields, let's delve into each of the requested areas:\n",
      "\n",
      "### 1. UNIQUE POSITIONING\n",
      "\n",
      "**Differentiation from Existing Work:**\n",
      "- **Current Sensor Data Only, No Memory Approach:** Your approach is distinct in its reliance solely on current sensor data without the use of memory stores or feedback loops. This is a significant departure from traditional methods that often rely on historical data or complex feedback mechanisms to guide navigation.\n",
      "- **Real-Time Feature Localization:** Unlike many existing methods that focus on static or pre-defined paths, your approach emphasizes real-time discovery and tracking of dynamic features such as critical points and bifurcations, which is less explored in the literature.\n",
      "- **Control Primitives Exploiting Topological Features:** The focus on developing control primitives that leverage the inherent topological features of vector fields (e.g., sources, sinks, saddles) is a novel aspect that sets your work apart from more conventional navigation strategies.\n",
      "\n",
      "### 2. GAP FILLING\n",
      "\n",
      "**Addressed Literature Gaps:**\n",
      "- **Limited Exploration of Vector Fields:** Your work directly addresses the gap in the exploration of vector fields, which are more complex than scalar fields due to their multi-parameter nature. This is a significant contribution given the literature's current focus on scalar fields.\n",
      "- **Economic Development and Testing:** By emphasizing the use of current sensor data without memory, your approach potentially reduces the complexity and cost associated with developing and testing control architectures, addressing the identified economic challenges.\n",
      "- **Complex Adaptive Navigation Control Objectives:** Your research pushes the boundaries by testing more complex adaptive navigation control objectives, which have been underexplored in existing literature.\n",
      "\n",
      "### 3. METHODOLOGICAL ADVANCES\n",
      "\n",
      "**Novelty of Using Current Sensor Readings:**\n",
      "- **Simplicity and Efficiency:** The use of only current sensor readings simplifies the computational requirements, making the system more efficient and potentially more robust to sensor noise and failures.\n",
      "- **Real-Time Adaptability:** This approach enhances the system's ability to adapt in real-time to changing environmental conditions, which is crucial for navigating dynamic vector fields.\n",
      "- **Reduced Computational Overhead:** By eliminating the need for memory and feedback loops, your method reduces computational overhead, which is advantageous for deploying on resource-constrained robotic platforms.\n",
      "\n",
      "### 4. COMPETITIVE COMPARISON\n",
      "\n",
      "| **Feature**                          | **Your Approach**                           | **Method A** (e.g., Kalman Filtering) | **Method B** (e.g., Lyapunov Methods) | **Method C** (e.g., Graph Theory) |\n",
      "|--------------------------------------|---------------------------------------------|---------------------------------------|---------------------------------------|-----------------------------------|\n",
      "| **Sensor Data Usage**                | Current only, no memory                     | Historical data and feedback          | Feedback loops                        | Graph-based memory structures     |\n",
      "| **Real-Time Adaptation**             | High                                        | Moderate                              | Moderate                              | Low                               |\n",
      "| **Computational Complexity**         | Low                                         | High                                  | Moderate                              | High                              |\n",
      "| **Focus on Vector Fields**           | Yes                                         | Limited                               | Limited                               | Limited                           |\n",
      "| **Control Primitives**               | Topological feature exploitation            | Not specified                         | Stability-focused                     | Path optimization                 |\n",
      "| **Economic Testing**                 | Emphasized                                  | Not emphasized                        | Not emphasized                        | Not emphasized                    |\n",
      "\n",
      "### 5. REVIEWER CONCERNS\n",
      "\n",
      "**Potential Criticisms:**\n",
      "- **Novelty Concerns:** Reviewers might question whether the \"current sensor data only\" approach is sufficiently novel or if it has been implicitly used in other contexts.\n",
      "- **Practical Implementation:** Concerns may arise regarding the practical implementation and effectiveness of the approach in real-world scenarios, especially in highly dynamic environments.\n",
      "- **Comparative Performance:** There might be skepticism about the comparative performance of your approach against established methods, particularly in terms of accuracy and robustness.\n",
      "\n",
      "### 6. POSITIONING STRATEGY\n",
      "\n",
      "**Framing for Maximum Impact:**\n",
      "- **Highlight Interdisciplinary Nature:** Emphasize the integration of robotics, control theory, and environmental sensing, showcasing the interdisciplinary nature of your work.\n",
      "- **Focus on Real-World Applications:** Stress the critical applications in environmental monitoring, search and rescue, and scientific exploration, which require advanced navigation capabilities.\n",
      "- **Emphasize Efficiency and Simplicity:** Position your approach as a more efficient and simpler alternative to existing methods, particularly for resource-constrained environments.\n",
      "- **Address Identified Gaps:** Clearly articulate how your work fills the identified gaps in the literature, particularly the exploration of vector fields and economic testing of control architectures.\n",
      "\n",
      "By strategically highlighting these aspects, you can effectively position your research as a significant contribution to the field of multirobot adaptive navigation in environmental vector fields.\n",
      "\n",
      "✓ Analysis saved to: research_positioning_analysis.md\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE!\n",
      "============================================================\n",
      "Generated files:\n",
      "- literature_meta_analysis_report.md\n",
      "- research_positioning_analysis.md\n",
      "\n",
      "Review these files for comprehensive insights into your research positioning!\n"
     ]
    }
   ],
   "source": [
    "# Literature Meta-Analysis and Research Positioning\n",
    "import re\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def load_paper_summaries(file_path=\"all_paper_summaries.md\"):\n",
    "    \"\"\"Load and parse the paper summaries from markdown file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Split by paper sections\n",
    "        papers = []\n",
    "        sections = content.split('# Analysis for ')\n",
    "        \n",
    "        for section in sections[1:]:  # Skip the header section\n",
    "            lines = section.split('\\n')\n",
    "            if lines:\n",
    "                filename = lines[0].strip()\n",
    "                paper_content = '\\n'.join(lines[1:])\n",
    "                papers.append({\n",
    "                    'filename': filename,\n",
    "                    'content': paper_content\n",
    "                })\n",
    "        \n",
    "        print(f\"Loaded {len(papers)} paper summaries\")\n",
    "        return papers\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {file_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading summaries: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_publication_years(papers):\n",
    "    \"\"\"Extract publication years from filenames and content\"\"\"\n",
    "    years = []\n",
    "    year_pattern = r'(19|20)\\d{2}'\n",
    "    \n",
    "    for paper in papers:\n",
    "        # Try to find year in filename first\n",
    "        filename_years = re.findall(year_pattern, paper['filename'])\n",
    "        content_years = re.findall(year_pattern, paper['content'][:500])  # Check first 500 chars\n",
    "        \n",
    "        found_years = filename_years + content_years\n",
    "        if found_years:\n",
    "            # Take the most recent reasonable year\n",
    "            valid_years = [int(y) for y in found_years if 1990 <= int(y) <= 2025]\n",
    "            if valid_years:\n",
    "                years.append(max(valid_years))\n",
    "            else:\n",
    "                years.append(None)\n",
    "        else:\n",
    "            years.append(None)\n",
    "    \n",
    "    return years\n",
    "\n",
    "def analyze_field_evolution(papers):\n",
    "    \"\"\"Analyze how the field has evolved over time\"\"\"\n",
    "    years = extract_publication_years(papers)\n",
    "    year_counts = Counter([y for y in years if y is not None])\n",
    "    \n",
    "    print(\"=== FIELD EVOLUTION ANALYSIS ===\")\n",
    "    print(f\"Papers with identifiable years: {len([y for y in years if y is not None])}/{len(papers)}\")\n",
    "    \n",
    "    if year_counts:\n",
    "        print(\"\\nPublication Timeline:\")\n",
    "        for year in sorted(year_counts.keys()):\n",
    "            print(f\"  {year}: {year_counts[year]} papers\")\n",
    "        \n",
    "        # Identify trends by decade\n",
    "        decades = defaultdict(int)\n",
    "        for year in year_counts:\n",
    "            decade = (year // 10) * 10\n",
    "            decades[decade] += year_counts[year]\n",
    "        \n",
    "        print(\"\\nDecade Distribution:\")\n",
    "        for decade in sorted(decades.keys()):\n",
    "            print(f\"  {decade}s: {decades[decade]} papers\")\n",
    "    \n",
    "    return year_counts\n",
    "\n",
    "def extract_themes_and_methods(papers):\n",
    "    \"\"\"Extract common themes and methodological approaches\"\"\"\n",
    "    \n",
    "    # Keywords to look for in different categories\n",
    "    theme_keywords = {\n",
    "        'Multi-Robot Systems': ['multi-robot', 'multi robot', 'swarm', 'collective', 'distributed', 'collaborative'],\n",
    "        'Navigation & Control': ['navigation', 'path planning', 'control', 'guidance', 'steering'],\n",
    "        'Vector Fields': ['vector field', 'flow field', 'gradient', 'potential field'],\n",
    "        'Environmental Sensing': ['environmental', 'sensing', 'monitoring', 'tracking'],\n",
    "        'Adaptive Systems': ['adaptive', 'learning', 'reinforcement', 'online'],\n",
    "        'Localization': ['localization', 'SLAM', 'positioning', 'mapping'],\n",
    "        'Formation Control': ['formation', 'consensus', 'coordination', 'synchronization'],\n",
    "        'Source Seeking': ['source seeking', 'source finding', 'plume tracking', 'gradient following']\n",
    "    }\n",
    "    \n",
    "    method_keywords = {\n",
    "        'Machine Learning': ['neural network', 'deep learning', 'reinforcement learning', 'ML', 'AI'],\n",
    "        'Kalman Filtering': ['kalman', 'EKF', 'UKF', 'particle filter'],\n",
    "        'Optimization': ['optimization', 'optimal', 'minimize', 'maximize', 'genetic algorithm'],\n",
    "        'Game Theory': ['game theory', 'nash equilibrium', 'cooperative', 'non-cooperative'],\n",
    "        'Graph Theory': ['graph', 'network', 'connectivity', 'topology'],\n",
    "        'Lyapunov Methods': ['lyapunov', 'stability', 'convergence'],\n",
    "        'Simulation': ['simulation', 'gazebo', 'matlab', 'simulink'],\n",
    "        'Real-world Testing': ['experiment', 'testbed', 'hardware', 'real robot', 'physical']\n",
    "    }\n",
    "    \n",
    "    theme_counts = defaultdict(int)\n",
    "    method_counts = defaultdict(int)\n",
    "    \n",
    "    for paper in papers:\n",
    "        content_lower = paper['content'].lower()\n",
    "        \n",
    "        # Count themes\n",
    "        for theme, keywords in theme_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in content_lower:\n",
    "                    theme_counts[theme] += 1\n",
    "                    break  # Count each theme only once per paper\n",
    "        \n",
    "        # Count methods\n",
    "        for method, keywords in method_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in content_lower:\n",
    "                    method_counts[method] += 1\n",
    "                    break  # Count each method only once per paper\n",
    "    \n",
    "    return dict(theme_counts), dict(method_counts)\n",
    "\n",
    "def extract_research_gaps(papers):\n",
    "    \"\"\"Extract commonly mentioned research gaps and limitations\"\"\"\n",
    "    gap_indicators = [\n",
    "        'limitation', 'challenge', 'future work', 'gap', 'problem', \n",
    "        'difficulty', 'issue', 'constraint', 'bottleneck'\n",
    "    ]\n",
    "    \n",
    "    common_gaps = []\n",
    "    \n",
    "    for paper in papers:\n",
    "        content_lower = paper['content'].lower()\n",
    "        \n",
    "        # Look for sections about research gaps\n",
    "        gap_sections = []\n",
    "        lines = content_lower.split('\\n')\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            if any(indicator in line for indicator in gap_indicators):\n",
    "                # Extract context around the gap mention\n",
    "                start = max(0, i-1)\n",
    "                end = min(len(lines), i+3)\n",
    "                context = ' '.join(lines[start:end])\n",
    "                gap_sections.append(context)\n",
    "        \n",
    "        common_gaps.extend(gap_sections)\n",
    "    \n",
    "    return common_gaps\n",
    "\n",
    "def create_research_taxonomy(theme_counts, method_counts, total_papers):\n",
    "    \"\"\"Create a taxonomy of research streams\"\"\"\n",
    "    \n",
    "    print(\"\\n=== RESEARCH TAXONOMY ===\")\n",
    "    \n",
    "    print(\"\\n1. PRIMARY RESEARCH THEMES:\")\n",
    "    sorted_themes = sorted(theme_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    for theme, count in sorted_themes:\n",
    "        percentage = (count / total_papers) * 100\n",
    "        print(f\"   • {theme}: {count} papers ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n2. METHODOLOGICAL APPROACHES:\")\n",
    "    sorted_methods = sorted(method_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    for method, count in sorted_methods:\n",
    "        percentage = (count / total_papers) * 100\n",
    "        print(f\"   • {method}: {count} papers ({percentage:.1f}%)\")\n",
    "    \n",
    "    return sorted_themes, sorted_methods\n",
    "\n",
    "def analyze_my_research_positioning(papers, my_field_description):\n",
    "    \"\"\"Analyze how my research positions relative to existing work\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MY RESEARCH POSITIONING ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Prepare analysis prompt\n",
    "    positioning_analysis = f\"\"\"\n",
    "Based on the literature analysis, I will now analyze how your research positions:\n",
    "\n",
    "YOUR RESEARCH: {my_field_description}\n",
    "\n",
    "LITERATURE THEMES FOUND:\n",
    "\"\"\"\n",
    "    \n",
    "    # Add theme analysis\n",
    "    theme_counts, method_counts = extract_themes_and_methods(papers)\n",
    "    \n",
    "    for theme, count in sorted(theme_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        positioning_analysis += f\"- {theme}: {count} papers\\n\"\n",
    "    \n",
    "    # Create the positioning prompt\n",
    "    positioning_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert academic analyst specializing in research positioning and novelty assessment.\"),\n",
    "        (\"human\", f\"\"\"\n",
    "Based on this literature analysis of {len(papers)} papers, analyze my research positioning:\n",
    "\n",
    "MY RESEARCH FIELD: {my_field_description}\n",
    "\n",
    "LITERATURE ANALYSIS SUMMARY:\n",
    "{positioning_analysis}\n",
    "\n",
    "Please provide a detailed analysis addressing:\n",
    "\n",
    "1. **UNIQUE POSITIONING**: How does my work differ from existing approaches? Be specific about what makes it unique.\n",
    "\n",
    "2. **GAP FILLING**: Which specific gaps from the literature does my work address? Quote specific limitations you can identify.\n",
    "\n",
    "3. **METHODOLOGICAL ADVANCES**: What novel aspects of my approach aren't covered in existing work?\n",
    "\n",
    "4. **COMPARATIVE ADVANTAGES**: Compare my method to the 3-5 most similar approaches from the literature.\n",
    "\n",
    "5. **POTENTIAL CRITICISMS**: What might reviewers say about novelty based on this literature? What are the strongest potential objections?\n",
    "\n",
    "6. **RESEARCH POSITIONING STRATEGY**: How should I position this work in papers to maximize perceived novelty and impact?\n",
    "\n",
    "Be thorough and critical. I want honest assessment of both strengths and potential weaknesses.\n",
    "        \"\"\")\n",
    "    ])\n",
    "    \n",
    "    return positioning_prompt\n",
    "\n",
    "def run_comprehensive_analysis(summaries_file=\"all_paper_summaries.md\"):\n",
    "    \"\"\"Run the complete meta-analysis\"\"\"\n",
    "    \n",
    "    print(\"COMPREHENSIVE LITERATURE META-ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load papers\n",
    "    papers = load_paper_summaries(summaries_file)\n",
    "    if not papers:\n",
    "        return\n",
    "    \n",
    "    # 1. Field Evolution Analysis\n",
    "    year_counts = analyze_field_evolution(papers)\n",
    "    \n",
    "    # 2. Theme and Method Analysis\n",
    "    theme_counts, method_counts = extract_themes_and_methods(papers)\n",
    "    \n",
    "    # 3. Create Research Taxonomy\n",
    "    sorted_themes, sorted_methods = create_research_taxonomy(theme_counts, method_counts, len(papers))\n",
    "    \n",
    "    # 4. Research Gaps Analysis\n",
    "    print(\"\\n=== COMMONLY MENTIONED RESEARCH GAPS ===\")\n",
    "    gaps = extract_research_gaps(papers)\n",
    "    \n",
    "    # Count most common gap-related terms\n",
    "    gap_words = []\n",
    "    for gap in gaps:\n",
    "        gap_words.extend(gap.split())\n",
    "    \n",
    "    gap_word_counts = Counter([word for word in gap_words if len(word) > 4])\n",
    "    print(\"\\nMost frequently mentioned challenges/gaps:\")\n",
    "    for word, count in gap_word_counts.most_common(15):\n",
    "        if count > 2:  # Only show words mentioned multiple times\n",
    "            print(f\"   • '{word}': {count} mentions\")\n",
    "    \n",
    "    # 5. Create summary report\n",
    "    create_summary_report(papers, theme_counts, method_counts, year_counts, gaps)\n",
    "    \n",
    "    return papers, theme_counts, method_counts, year_counts\n",
    "\n",
    "def create_summary_report(papers, theme_counts, method_counts, year_counts, gaps):\n",
    "    \"\"\"Create a comprehensive summary report\"\"\"\n",
    "    \n",
    "    report = f\"\"\"\n",
    "# LITERATURE META-ANALYSIS SUMMARY REPORT\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## OVERVIEW\n",
    "- Total papers analyzed: {len(papers)}\n",
    "- Papers with publication years: {len([y for y in extract_publication_years(papers) if y is not None])}\n",
    "\n",
    "## TOP RESEARCH THEMES\n",
    "\"\"\"\n",
    "    \n",
    "    for theme, count in sorted(theme_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        percentage = (count / len(papers)) * 100\n",
    "        report += f\"- **{theme}**: {count} papers ({percentage:.1f}%)\\n\"\n",
    "    \n",
    "    report += \"\\n## TOP METHODOLOGICAL APPROACHES\\n\"\n",
    "    \n",
    "    for method, count in sorted(method_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        percentage = (count / len(papers)) * 100\n",
    "        report += f\"- **{method}**: {count} papers ({percentage:.1f}%)\\n\"\n",
    "    \n",
    "    if year_counts:\n",
    "        report += \"\\n## TEMPORAL DISTRIBUTION\\n\"\n",
    "        for year in sorted(year_counts.keys(), reverse=True)[:10]:\n",
    "            report += f\"- **{year}**: {year_counts[year]} papers\\n\"\n",
    "    \n",
    "    # Save report\n",
    "    with open(\"literature_meta_analysis_report.md\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(f\"\\n✓ Comprehensive report saved to: literature_meta_analysis_report.md\")\n",
    "\n",
    "def analyze_research_positioning_with_llm(papers):\n",
    "    \"\"\"Use LLM to analyze research positioning\"\"\"\n",
    "    \n",
    "    # Extract key information for positioning analysis\n",
    "    theme_counts, method_counts = extract_themes_and_methods(papers)\n",
    "    gaps = extract_research_gaps(papers)\n",
    "    years = extract_publication_years(papers)\n",
    "    \n",
    "    # Create comprehensive context for LLM\n",
    "    literature_context = f\"\"\"\n",
    "LITERATURE ANALYSIS SUMMARY ({len(papers)} papers):\n",
    "\n",
    "TOP RESEARCH THEMES:\n",
    "\"\"\"\n",
    "    \n",
    "    for theme, count in sorted(theme_counts.items(), key=lambda x: x[1], reverse=True)[:8]:\n",
    "        percentage = (count / len(papers)) * 100\n",
    "        literature_context += f\"- {theme}: {count} papers ({percentage:.1f}%)\\n\"\n",
    "    \n",
    "    literature_context += \"\\nTOP METHODS:\\n\"\n",
    "    for method, count in sorted(method_counts.items(), key=lambda x: x[1], reverse=True)[:8]:\n",
    "        percentage = (count / len(papers)) * 100\n",
    "        literature_context += f\"- {method}: {count} papers ({percentage:.1f}%)\\n\"\n",
    "    \n",
    "    # Add time span if years are available\n",
    "    valid_years = [y for y in years if y]\n",
    "    if valid_years:\n",
    "        literature_context += f\"\\nTIME SPAN: {min(valid_years)}-{max(valid_years)} (identifiable papers)\"\n",
    "    else:\n",
    "        literature_context += f\"\\nTIME SPAN: Publication years not identifiable from filenames\"\n",
    "    \n",
    "    # Create positioning analysis prompt\n",
    "    positioning_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert academic analyst specializing in research positioning, novelty assessment, and competitive analysis for academic publications.\"),\n",
    "        (\"human\", f\"\"\"\n",
    "Based on this comprehensive literature analysis, provide a detailed research positioning analysis:\n",
    "\n",
    "MY RESEARCH: {MY_FIELD_DESCRIPTION}\n",
    "\n",
    "{literature_context}\n",
    "\n",
    "SAMPLE RESEARCH GAPS IDENTIFIED:\n",
    "{chr(10).join(gaps[:5])}\n",
    "\n",
    "Provide detailed analysis for:\n",
    "\n",
    "1. **UNIQUE POSITIONING**: How does my multirobot adaptive navigation approach differ from existing work? What makes the \"current sensor data only, no memory\" approach novel?\n",
    "\n",
    "2. **GAP FILLING**: Which specific literature gaps does my work address? Be explicit about limitations in existing work.\n",
    "\n",
    "3. **METHODOLOGICAL ADVANCES**: What's novel about using only current sensor readings for adaptive navigation in vector fields?\n",
    "\n",
    "4. **COMPETITIVE COMPARISON**: Create a detailed comparison table showing my approach vs. the 3-5 most similar methods from this literature.\n",
    "\n",
    "5. **REVIEWER CONCERNS**: What might reviewers criticize about novelty? What are the strongest potential objections?\n",
    "\n",
    "6. **POSITIONING STRATEGY**: How should I frame this work to maximize perceived contribution and impact?\n",
    "\n",
    "Be thorough, critical, and specific. Reference the literature analysis data provided.\n",
    "        \"\"\")\n",
    "    ])\n",
    "    \n",
    "    # Use the same LLM from the main script\n",
    "    try:\n",
    "        chain = positioning_prompt | llm\n",
    "        response = chain.invoke({})\n",
    "        positioning_analysis = response.content if hasattr(response, 'content') else str(response)\n",
    "        \n",
    "        # Save positioning analysis\n",
    "        with open(\"research_positioning_analysis.md\", \"w\", encoding='utf-8') as f:\n",
    "            f.write(f\"# RESEARCH POSITIONING ANALYSIS\\n\\n\")\n",
    "            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "            f.write(positioning_analysis)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RESEARCH POSITIONING ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        print(positioning_analysis)\n",
    "        print(f\"\\n✓ Analysis saved to: research_positioning_analysis.md\")\n",
    "        \n",
    "        return positioning_analysis\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM positioning analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting comprehensive literature meta-analysis...\")\n",
    "    \n",
    "    # Run the analysis\n",
    "    papers, theme_counts, method_counts, year_counts = run_comprehensive_analysis()\n",
    "    \n",
    "    # Generate LLM-based positioning analysis\n",
    "    if papers:\n",
    "        print(\"\\nGenerating AI-powered research positioning analysis...\")\n",
    "        positioning_analysis = analyze_research_positioning_with_llm(papers)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Generated files:\")\n",
    "    print(\"- literature_meta_analysis_report.md\")\n",
    "    print(\"- research_positioning_analysis.md\")\n",
    "    print(\"\\nReview these files for comprehensive insights into your research positioning!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
